{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will understand the steps of static web scrapping to extract a table from any website in simple steps. At first, we will see how to use pandas to extract tables from a website.\n",
    "\n",
    "Python provides a powerful library BeautifulSoup for web scraping. As a second method, we will learn how to use BeautifulSoup to extract tables from a website. Apart from tables, we can extract list, texts, paragraphs, headers and all sort of things present on the website using BrautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                Company                           Website\n",
      "0      1                Walmart      http://www.stock.walmart.com\n",
      "1      2            Exxon Mobil         http://www.exxonmobil.com\n",
      "2      3                  Apple              http://www.apple.com\n",
      "3      4     Berkshire Hathaway  http://www.berkshirehathaway.com\n",
      "4      5             Amazon.com             http://www.amazon.com\n",
      "..   ...                    ...                               ...\n",
      "95    96                 AbbVie             http://www.abbvie.com\n",
      "96    97                    CHS             http://www.chsinc.com\n",
      "97    98  Capital One Financial         http://www.capitalone.com\n",
      "98    99            Progressive        http://www.progressive.com\n",
      "99   100              Coca-Cola   http://www.coca-colacompany.com\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# using pandas\n",
    "dfs = pd.read_html('https://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites')\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].to_csv('fortune_100.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.zyxware.com/articles/4344/list-of-fortune-500-companies-and-their-websites'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" dir=\"ltr\" prefix=\"content: http://purl.org/rss/1.0/modules/content/  dc: http://purl.org/dc/terms/  foaf: http://xmlns.com/foaf/0.1/  og: http://ogp.me/ns#  rdfs: http://www.w3.org/2000/01/rdf-schema#  schema: http://schema.org/  sioc: http://rdfs.org/sioc/ns#  sioct: http://rdfs.org/sioc/types#  skos: http://www.w3.org/2004/02/skos/core#  xsd: http://www.w3.org/2001/XMLSchema# \">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "<script>dataLayer = [];dataLayer.push({\"tag\": \n"
     ]
    }
   ],
   "source": [
    "print(page.text[0:500]) # Looking at first 500 characters of the response which we got from the url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the output\n",
    "The above response is in html format which is rendered by browsers to create the content on the website. Beautiful Soup gives us similar functionality of extracting useful informattion from the above content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup is a BeautifulSoup object from which we can extract any relevant data from the webpage. Following is the list of commoly used tags in html:\n",
    "\n",
    "`Tags` | `Description`\n",
    "--- | ---\n",
    "!DOCTYPE | Defines the document type\n",
    "html | Defines an HTML document\n",
    "head | Contains metadata/information for the document\n",
    "title | Defines a title for the document\n",
    "body | Defines the document's body\n",
    "h1 to <h6 | Defines HTML headings\n",
    "p | Defines a paragraph\n",
    "br | Inserts a single line break\n",
    "hr | Defines a thematic change in the content\n",
    "!--...-- |\tDefines a comment\n",
    "ul | Defines an unordered list\n",
    "ol | Defines an ordered list\n",
    "li | Defines a list item\n",
    "dir | Not supported in HTML5. Use ul instead. Defines a directory list\n",
    "dl | Defines a description list\n",
    "dt | Defines a term/name in a description list\n",
    "dd | Defines a description of a term/name in a description list\n",
    "table|Defines a table\n",
    "caption|Defines a table caption\n",
    "th|Defines a header cell in a table\n",
    "tr|Defines a row in a table\n",
    "td|Defines a cell in a table\n",
    "thead|Groups the header content in a table\n",
    "tbody|Groups the body content in a table\n",
    "tfoot|Groups the footer content in a table\n",
    "col|Specifies column properties for each column within a colgroup element\n",
    "colgroup | Specifies a group of one or more columns in a table for formatting\n",
    "\n",
    "On our [target website](https://fortune.com/fortune500/2019/search/) we are trying to extract a table. So we will use table tag to extract the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')\n",
    "table_rows = table.find_all('tr')\n",
    "fortune = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [i.text for i in td]\n",
    "    fortune.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>http://www.stock.walmart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>http://www.exxonmobil.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Apple</td>\n",
       "      <td>http://www.apple.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>http://www.berkshirehathaway.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                   1                                 2\n",
       "1  1             Walmart      http://www.stock.walmart.com\n",
       "2  2         Exxon Mobil         http://www.exxonmobil.com\n",
       "3  3               Apple              http://www.apple.com\n",
       "4  4  Berkshire Hathaway  http://www.berkshirehathaway.com\n",
       "5  5          Amazon.com             http://www.amazon.com"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune = pd.DataFrame(fortune)\n",
    "fortune.drop(0, axis = 0, inplace = True)\n",
    "fortune.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "That's it for now. In this notebook we learnt two methods to extract tables from a website - by using pandas and beautifulsoup. Please upvote this [notebook](https://www.kaggle.com/prasun2106/extracting-tables-from-any-website?scriptVersionId=33926509) if you find above code helpful, as it motivates me to write more tutorials for beginners. You can visit my website [datamaniac.tech](https://www.datamaniac.tech) for more such tutorials. Follow me on [Kaggle](https://www.kaggle.com/prasun2106), [Github](https://github.com/prasun2106) and contact me on [LinkedIn](https://www.linkedin.com/in/prasun-kumar-8250a5119/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
